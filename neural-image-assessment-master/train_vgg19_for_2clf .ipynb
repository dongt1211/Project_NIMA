{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import Callback, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# System libraries\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dataset\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError\n",
    "dataset = \"/home/bkcs/NIMA/dataset3/Low/\"\n",
    "path = Path(dataset).rglob(\"*.jpg\")\n",
    "for img_p in os.listdir(dataset):\n",
    "    try:\n",
    "        img = Image.open(os.path.join(dataset, img_p))\n",
    "    except:\n",
    "        os.remove(os.path.join(dataset, img_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "'''\n",
    "Checks all images from the AVA dataset if they have corrupted jpegs, and lists them for removal.\n",
    "\n",
    "Removal must be done manually !\n",
    "'''\n",
    "\n",
    "base_images_path = '/home/bkcs/NIMA/dataset2/LowHigh/'\n",
    "ava_dataset_path = '/home/bkcs/NIMA/AVA.txt'\n",
    "\n",
    "\n",
    "#print(files)\n",
    "train_image_paths = []\n",
    "train_scores = []\n",
    "\n",
    "print(\"Loading training set and val set\")\n",
    "with open(ava_dataset_path, mode='r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        token = line.split()\n",
    "        id = int(token[1])\n",
    "\n",
    "        values = np.array(token[2:12], dtype='float32')\n",
    "        values /= values.sum()\n",
    "\n",
    "        file_path = base_images_path + str(id) + '.jpg'\n",
    "        if os.path.exists(file_path):\n",
    "            train_image_paths.append(file_path)\n",
    "            train_scores.append(values)\n",
    "\n",
    "        count = 255000 // 20\n",
    "        if i % count == 0 and i != 0:\n",
    "            print('Loaded %0.2f of the dataset' % (i / 255000. * 100))\n",
    "\n",
    "\n",
    "train_image_paths = np.array(train_image_paths)\n",
    "train_scores = np.array(train_scores, dtype='float32')\n",
    "\n",
    "# val_image_paths = train_image_paths[-50:]\n",
    "# val_scores = train_scores[-50:]\n",
    "# train_image_paths = train_image_paths[:-50]\n",
    "# train_scores = train_scores[:-50]\n",
    "\n",
    "def parse_data(filename):\n",
    "    image = tf.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return image\n",
    "\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    count = 0\n",
    "    fn = tf.placeholder(dtype=tf.string)\n",
    "    img = parse_data(fn)\n",
    "\n",
    "    for path in train_image_paths:\n",
    "        try:\n",
    "            sess.run(img, feed_dict={fn: path})\n",
    "        except Exception as e:\n",
    "            print(path, \"failed to load !\")\n",
    "            count += 1\n",
    "            os.remove(path)\n",
    "\n",
    "    print(count, \"images failed to load !\")\n",
    "\n",
    "print(\"All done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = (224, 224)\n",
    "dataset = \"/home/bkcs/NIMA/dataset2\"\n",
    "a = {\"LowHigh\": 0, \"Medium\":1}\n",
    "def convert_path_to_df(dataset):\n",
    "    labels = []\n",
    "    image_dir = Path(dataset)\n",
    "\n",
    "    # Get filepaths and labels\n",
    "    filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.PNG'))\n",
    "\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "    # for i in labels1:\n",
    "    #     labels.append(a[i])\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    # Concatenate filepaths and labels\n",
    "    image_df = pd.concat([filepaths, labels], axis=1)\n",
    "    return image_df\n",
    "\n",
    "image_df = convert_path_to_df(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/bkcs/NIMA/dataset2/Medium/160409.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/bkcs/NIMA/dataset2/Medium/446171.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/bkcs/NIMA/dataset2/Medium/754457.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/bkcs/NIMA/dataset2/Medium/44807.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/bkcs/NIMA/dataset2/Medium/598245.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249126</th>\n",
       "      <td>/home/bkcs/NIMA/dataset2/LowHigh/492636.jpg</td>\n",
       "      <td>LowHigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249127</th>\n",
       "      <td>/home/bkcs/NIMA/dataset2/LowHigh/707126.jpg</td>\n",
       "      <td>LowHigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249128</th>\n",
       "      <td>/home/bkcs/NIMA/dataset2/LowHigh/607641.jpg</td>\n",
       "      <td>LowHigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249129</th>\n",
       "      <td>/home/bkcs/NIMA/dataset2/LowHigh/766089.jpg</td>\n",
       "      <td>LowHigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249130</th>\n",
       "      <td>/home/bkcs/NIMA/dataset2/LowHigh/845020.jpg</td>\n",
       "      <td>LowHigh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249131 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Filepath    Label\n",
       "0        /home/bkcs/NIMA/dataset2/Medium/160409.jpg   Medium\n",
       "1        /home/bkcs/NIMA/dataset2/Medium/446171.jpg   Medium\n",
       "2        /home/bkcs/NIMA/dataset2/Medium/754457.jpg   Medium\n",
       "3         /home/bkcs/NIMA/dataset2/Medium/44807.jpg   Medium\n",
       "4        /home/bkcs/NIMA/dataset2/Medium/598245.jpg   Medium\n",
       "...                                             ...      ...\n",
       "249126  /home/bkcs/NIMA/dataset2/LowHigh/492636.jpg  LowHigh\n",
       "249127  /home/bkcs/NIMA/dataset2/LowHigh/707126.jpg  LowHigh\n",
       "249128  /home/bkcs/NIMA/dataset2/LowHigh/607641.jpg  LowHigh\n",
       "249129  /home/bkcs/NIMA/dataset2/LowHigh/766089.jpg  LowHigh\n",
       "249130  /home/bkcs/NIMA/dataset2/LowHigh/845020.jpg  LowHigh\n",
       "\n",
       "[249131 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "def apply_downsampling(image_df):\n",
    "    # Separate majority and minority classes\n",
    "    \n",
    "    majority_df = image_df[image_df['Label'] == 'Medium']\n",
    "    minority_df_Low = image_df[image_df['Label'] == \"Low\"]\n",
    "    minority_df_High = image_df[image_df['Label'] == \"High\"]\n",
    "\n",
    "    # Oversample the minority class to have the same number of instances as the majority class\n",
    "    downsampled_majority_df_1 = resample(majority_df ,n_samples=len(minority_df_Low), replace=True, random_state=42)\n",
    "    #oversampled_minority_df_2 = resample(minority_df_High, n_samples=len(majority_df), replace=True, random_state=42)\n",
    "    # Combine the oversampled minority class and the majority class\n",
    "    oversampled_df = pd.concat([minority_df_Low,minority_df_High, downsampled_majority_df_1, ])\n",
    "\n",
    "    return oversampled_df\n",
    "#image_df = apply_downsampling(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "def hybrid_sampling(image_df):\n",
    "    # Separate majority and minority classes\n",
    "    \n",
    "    majority_df = image_df[image_df['Label'] == 'Medium']\n",
    "    minority_df_LowHigh = image_df[image_df['Label'] == \"LowHigh\"]\n",
    "   \n",
    "    n_samples = (len(majority_df)+len(minority_df_LowHigh))//2\n",
    "    # Oversample the minority class to have the same number of instances as the majority class\n",
    "    downsampled_majority_df = resample( majority_df ,n_samples=n_samples, replace=True, random_state=42)\n",
    "    oversampled_minority_df_1 = resample(minority_df_LowHigh, n_samples=n_samples, replace=True, random_state=42)\n",
    "    # Combine the oversampled minority class and the majority class\n",
    "    oversampled_df = pd.concat( [oversampled_minority_df_1, downsampled_majority_df ])\n",
    "\n",
    "    return oversampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39860 validated image filenames belonging to 2 classes.\n",
      "Found 159444 validated image filenames belonging to 2 classes.\n",
      "Found 49827 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Separate in train and test data\n",
    "train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "train_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
    "    validation_split=0.2\n",
    ")\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "#train_df = hybrid_sampling(train_df)\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
    ")\n",
    "# Split the data into three categories.\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 19:36:17.763407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n",
      "238131\n",
      "0.5230965309010587\n",
      "11.324136363636363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 19:36:17.802812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 19:36:17.803003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 19:36:17.803942: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-11 19:36:17.804596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 19:36:17.805003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 19:36:17.805160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 19:36:18.325092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 19:36:18.325348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 19:36:18.325498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 19:36:18.325608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9849 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "lowhigh = image_df['Label'].value_counts()['LowHigh']\n",
    "print(lowhigh)\n",
    "medium = image_df['Label'].value_counts()['Medium']\n",
    "print(medium)\n",
    "weight_for_medium = (1 / medium) * (len(image_df) / 2.0) \n",
    "print(weight_for_medium)\n",
    "weight_for_lowhigh = (1 / lowhigh) * (len(image_df) / 2.0)\n",
    "print(weight_for_lowhigh)\n",
    "class_weight = {0: weight_for_lowhigh, 1: weight_for_medium}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.efficientnet.EfficientNetB4(\n",
    "    input_shape=(224, 224, 3),\n",
    "    weights = 'imagenet',\n",
    "    include_top=False,\n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "pretrained_model.trainable = True\n",
    "# Create checkpoint callback\n",
    "checkpoint_path = \"/home/bkcs/NIMA/weights/EfficientNetB4_classification_weights_cls_weight_2cls_1(official2).h5\"\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
    "                                      save_weights_only=True,\n",
    "                                      monitor=\"val_prc\",\n",
    "                                      save_best_only=True)\n",
    "\n",
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "early_stopping = EarlyStopping(monitor = \"val_prc\", # watch the val loss metric\n",
    "                               patience = 15,\n",
    "                               restore_best_weights = True) \n",
    "# if val loss decreases for 3 epochs in a row, stop training\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_prc', factor=0.2, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augment\n",
    "augment = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Resizing(224,224),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.1)\n",
    "])\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 19:36:47.292663: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2023-07-11 19:36:48.237167: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.79GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-11 19:36:48.373160: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-11 19:36:48.380037: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.63GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-11 19:36:48.437945: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.79GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  33/4983 [..............................] - ETA: 34:58 - loss: 0.1530 - tp: 974.0000 - fp: 82.0000 - tn: 974.0000 - fn: 82.0000 - accuracy: 0.9223 - precision: 0.9223 - recall: 0.9223 - auc: 0.9736 - prc: 0.9712"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[39m.\u001b[39mload_weights(\u001b[39m'\u001b[39m\u001b[39m/home/bkcs/NIMA/weights/EfficientNetB4_classification_weights_cls_weight_2cls_1(official).h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[39m=\u001b[39mAdam(\u001b[39m0.0001\u001b[39m),\n\u001b[1;32m     18\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m     metrics\u001b[39m=\u001b[39mMETRICS\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     22\u001b[0m     train_images,\n\u001b[1;32m     23\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_images),\n\u001b[1;32m     24\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_images,\n\u001b[1;32m     25\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(val_images),\n\u001b[1;32m     26\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     27\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     28\u001b[0m         early_stopping,\n\u001b[1;32m     29\u001b[0m         checkpoint_callback,\n\u001b[1;32m     30\u001b[0m         reduce_lr\n\u001b[1;32m     31\u001b[0m     ],\n\u001b[1;32m     32\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight\n\u001b[1;32m     33\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = pretrained_model.input\n",
    "x = augment(inputs)\n",
    "x = Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.load_weights('/home/bkcs/NIMA/weights/EfficientNetB4_classification_weights_cls_weight_2cls_1(official).h5')\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=METRICS\n",
    ")\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    steps_per_epoch=len(train_images),\n",
    "    validation_data=val_images,\n",
    "    validation_steps=len(val_images),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        checkpoint_callback,\n",
    "        reduce_lr\n",
    "    ],\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify 2 classes: LowHigh and Medium (VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/bkcs/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow==2.10 in /home/bkcs/.local/lib/python3.10/site-packages (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (1.54.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (3.8.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (16.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (23.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow==2.10) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.10) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (0.32.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorflow==2.10) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow==2.10) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/bkcs/.local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/bkcs/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/bkcs/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/bkcs/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/bkcs/.local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/bkcs/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/bkcs/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow==2.10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 19:35:46.403321: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-11 19:35:46.552398: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-11 19:35:47.216169: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-07-11 19:35:47.216273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-07-11 19:35:47.216282: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/bkcs/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting keras==2.10\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.8.0\n",
      "    Uninstalling keras-2.8.0:\n",
      "      Successfully uninstalled keras-2.8.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.8.0 requires keras<2.9,>=2.8.0rc0, but you have keras 2.10.0 which is incompatible.\n",
      "tensorflow-gpu 2.8.0 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.10.0\n"
     ]
    }
   ],
   "source": [
    "! pip install keras==2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Model\n",
    "# pretrained_model = tf.keras.applications.vgg19.VGG19(\n",
    "#     input_shape=(224, 224, 3),\n",
    "#     # weights = 'imagenet',\n",
    "#     include_top=False,\n",
    "#     pooling='max'\n",
    "# )\n",
    "# inputs = pretrained_model.input\n",
    "# x = Dense(128, activation='relu')(pretrained_model.output)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.45)(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.45)(x)\n",
    "# outputs = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# model.load_weights('/home/bkcs/NIMA/weights/VGG19_classification_weights_hybrid_2cls(official).h5')\n",
    "# model.compile(\n",
    "#     optimizer=Adam(0.00001),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify 2 classes: Low and High (VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify 2 classes: Low and High (INceptionResnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify 2 classes: LowHigh and Medium (EfficientnetB4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Loss: 0.37953\n",
      "Test Accuracy: 88.75%\n",
      "[0.3795323669910431, 0.8874906897544861]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 05:53:56.747976: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2023-06-01 05:53:56.766949: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.62GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "pretrained_model = tf.keras.applications.efficientnet.EfficientNetB4(\n",
    "    input_shape=(224, 224, 3),\n",
    "    weights = 'imagenet',\n",
    "    include_top=False,\n",
    "    pooling='max'\n",
    ")\n",
    "inputs = pretrained_model.input\n",
    "x = augment(inputs)\n",
    "x = Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.load_weights('/home/bkcs/NIMA/weights/EfficientNetB4_classification_weights_cls_weight_2cls_1(official2).h5')\n",
    "\\\n",
    "model.compile(\n",
    "    optimizer=Adam(0.00001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     LowHigh       0.16      0.36      0.22      2194\n",
      "      Medium       0.97      0.91      0.94     47633\n",
      "\n",
      "    accuracy                           0.89     49827\n",
      "   macro avg       0.56      0.64      0.58     49827\n",
      "weighted avg       0.93      0.89      0.91     49827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  792,  1402],\n",
       "       [ 4204, 43429]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify 2 classes: Low and High (EfficientnetB4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
