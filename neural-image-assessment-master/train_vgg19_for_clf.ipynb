{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import Callback, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# System libraries\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkcs/anaconda3/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "/home/bkcs/anaconda3/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "#check dataset\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError\n",
    "dataset = \"/home/bkcs/NIMA/test_img_4-5, 6-7\"\n",
    "path = Path(dataset).rglob(\"*.jpg\")\n",
    "for img_p in os.listdir(dataset):\n",
    "    try:\n",
    "        img = Image.open(os.path.join(dataset, img_p))\n",
    "    except PIL.UnidentifiedImageError:\n",
    "        os.remove(os.path.join(dataset, img_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "TARGET_SIZE = (400, 400)\n",
    "dataset = \"/home/bkcs/NIMA/dataset4\"\n",
    "def convert_path_to_df(dataset):\n",
    "    image_dir = Path(dataset)\n",
    "\n",
    "    # Get filepaths and labels\n",
    "    filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.PNG'))\n",
    "\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    # Concatenate filepaths and labels\n",
    "    image_df = pd.concat([filepaths, labels], axis=1)\n",
    "    return image_df\n",
    "\n",
    "image_df = convert_path_to_df(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/bkcs/NIMA/dataset4/Medium/446171.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/bkcs/NIMA/dataset4/Medium/44807.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/bkcs/NIMA/dataset4/Medium/598245.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/bkcs/NIMA/dataset4/Medium/785652.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/bkcs/NIMA/dataset4/Medium/6493.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139042</th>\n",
       "      <td>/home/bkcs/NIMA/dataset4/High/411332.jpg</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139043</th>\n",
       "      <td>/home/bkcs/NIMA/dataset4/High/473409.jpg</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139044</th>\n",
       "      <td>/home/bkcs/NIMA/dataset4/High/502630.jpg</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139045</th>\n",
       "      <td>/home/bkcs/NIMA/dataset4/High/22284.jpg</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139046</th>\n",
       "      <td>/home/bkcs/NIMA/dataset4/High/707126.jpg</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139047 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filepath   Label\n",
       "0       /home/bkcs/NIMA/dataset4/Medium/446171.jpg  Medium\n",
       "1        /home/bkcs/NIMA/dataset4/Medium/44807.jpg  Medium\n",
       "2       /home/bkcs/NIMA/dataset4/Medium/598245.jpg  Medium\n",
       "3       /home/bkcs/NIMA/dataset4/Medium/785652.jpg  Medium\n",
       "4         /home/bkcs/NIMA/dataset4/Medium/6493.jpg  Medium\n",
       "...                                            ...     ...\n",
       "139042    /home/bkcs/NIMA/dataset4/High/411332.jpg    High\n",
       "139043    /home/bkcs/NIMA/dataset4/High/473409.jpg    High\n",
       "139044    /home/bkcs/NIMA/dataset4/High/502630.jpg    High\n",
       "139045     /home/bkcs/NIMA/dataset4/High/22284.jpg    High\n",
       "139046    /home/bkcs/NIMA/dataset4/High/707126.jpg    High\n",
       "\n",
       "[139047 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "def apply_oversampling(image_df):\n",
    "    # Separate majority and minority classes\n",
    "    \n",
    "    majority_df = image_df[image_df['Label'] == 'Medium']\n",
    "    minority_df_Low = image_df[image_df['Label'] == \"Low\"]\n",
    "    minority_df_High = image_df[image_df['Label'] == \"High\"]\n",
    "\n",
    "    # Oversample the minority class to have the same number of instances as the majority class\n",
    "    oversampled_minority_df_1 = resample(minority_df_Low ,n_samples=len(majority_df), replace=True, random_state=42)\n",
    "    oversampled_minority_df_2 = resample(minority_df_High, n_samples=len(majority_df), replace=True, random_state=42)\n",
    "    # Combine the oversampled minority class and the majority class\n",
    "    oversampled_df = pd.concat( [oversampled_minority_df_1, majority_df, oversampled_minority_df_2 ])\n",
    "\n",
    "    return oversampled_df\n",
    "# image_df = apply_oversampling(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "def apply_downsampling(image_df):\n",
    "    # Separate majority and minority classes\n",
    "    \n",
    "    majority_df = image_df[image_df['Label'] == 'Medium']\n",
    "    minority_df_Low = image_df[image_df['Label'] == \"Low\"]\n",
    "    minority_df_High = image_df[image_df['Label'] == \"High\"]\n",
    "\n",
    "    # Oversample the minority class to have the same number of instances as the majority class\n",
    "    downsampled_majority_df_1 = resample(majority_df ,n_samples=len(minority_df_Low), replace=True, random_state=42)\n",
    "    upsampled_majority_df_2 = resample(minority_df_High  ,n_samples=len(minority_df_Low), replace=True, random_state=42)\n",
    "    # Combine the oversampled minority class and the majority class\n",
    "    downsampled_df = pd.concat( [upsampled_majority_df_2 ,   minority_df_Low , downsampled_majority_df_1 ])\n",
    "\n",
    "    return downsampled_df\n",
    "#image_df = apply_downsampling(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "def hybrid_sampling(image_df):\n",
    "    # Separate majority and minority classes\n",
    "    \n",
    "    majority_df = image_df[image_df['Label'] == 'Medium']\n",
    "    minority_df_Low = image_df[image_df['Label'] == \"Low\"]\n",
    "    minority_df_High = image_df[image_df['Label'] == \"High\"]\n",
    "    n_samples = (len(majority_df) + len(minority_df_Low)+len(minority_df_High))//3 #(len(majority_df)\n",
    "    # Oversample the minority class to have the same number of instances as the majority class\n",
    "    downsampled_majority_df = resample( majority_df ,n_samples=n_samples, replace=True, random_state=42)\n",
    "    oversampled_minority_df_1 = resample(minority_df_High, n_samples=n_samples, replace=True, random_state=42)\n",
    "    oversampled_minority_df_2 = resample(minority_df_Low, n_samples=n_samples, replace=True, random_state=42)\n",
    "    # Combine the oversampled minority class and the majority class\n",
    "    oversampled_df = pd.concat( [oversampled_minority_df_1, downsampled_majority_df , oversampled_minority_df_2 ])\n",
    "\n",
    "    return oversampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11123 validated image filenames belonging to 3 classes.\n",
      "Found 100114 validated image filenames belonging to 3 classes.\n",
      "<keras.preprocessing.image.DataFrameIterator object at 0x7f737c601b70>\n",
      "<keras.preprocessing.image.DataFrameIterator object at 0x7f73e45a8730>\n",
      "Found 27810 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Separate in train and test data\n",
    "train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)\n",
    "#train_df = hybrid_sampling(train_df)\n",
    "\n",
    "train_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,\n",
    "    validation_split=0.1\n",
    ")\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,\n",
    ")\n",
    "# Split the data into three categories.\n",
    "train_df = hybrid_sampling(train_df)\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "print(train_images)\n",
    "\n",
    "print(val_images)\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "# Load the pretained model\n",
    "\n",
    "pretrained_model = tf.keras.applications.efficientnet.EfficientNetB4(\n",
    "    input_shape=(400, 400, 3),\n",
    "    weights = 'imagenet',\n",
    "    include_top=False,\n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "pretrained_model.trainable = True\n",
    "# Create checkpoint callback\n",
    "checkpoint_path = \"/home/bkcs/NIMA/weights/EfficientNetB4_classification_weights_hybridsample_3cls(5-6)(400x400).h5\"\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
    "                                      save_weights_only=True,\n",
    "                                      monitor=\"val_accuracy\",\n",
    "                                      save_best_only=True)\n",
    "\n",
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "early_stopping = EarlyStopping(monitor = \"val_accuracy\", # watch the val loss metric\n",
    "                               patience = 5,\n",
    "                               restore_best_weights = True) \n",
    "# if val loss decreases for 3 epochs in a row, stop training\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augment\n",
    "crop_size = (150, 150)\n",
    "augment = tf.keras.Sequential([\n",
    "  #tf.keras.layers.experimental.preprocessing.Resizing(224,224),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "  #tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomCrop(*crop_size),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "])\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 20:49:02.246733: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-11 20:49:02.895271: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-11 20:49:04.864172: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-07-11 20:49:04.864326: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib:/home/bkcs/anaconda3/lib/:/home/bkcs/anaconda3/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-07-11 20:49:04.864337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-07-11 20:49:07.281867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 20:49:07.467903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-11 20:49:07.468252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
      "  NVIDIA GeForce GTX 1080 Ti, compute capability 6.1\n",
      "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 09:00:27.722324: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pretrained_model.input\n",
    "x = augment(inputs)\n",
    "x = Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "\n",
    "\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.load_weights('/home/bkcs/NIMA/weights/EfficientNetB4_classification_weights_hybridsample_3cls(5-6)(400x400).h5')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_images,\n",
    "#     steps_per_epoch=len(train_images),\n",
    "#     validation_data=val_images,\n",
    "#     validation_steps=len(val_images),\n",
    "#     epochs=100,\n",
    "#     callbacks=[\n",
    "#         early_stopping,\n",
    "#         checkpoint_callback,\n",
    "#         reduce_lr\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on separate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3477/3477 [==============================] - 281s 80ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  371/12515 [..............................] - ETA: 1:09:33 - loss: 0.6282 - tp: 2140.0000 - fp: 707.0000 - tn: 5229.0000 - fn: 828.0000 - accuracy: 0.8276 - precision: 0.7517 - recall: 0.7210 - auc: 0.8972 - prc: 0.8137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkcs/anaconda3/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12515/12515 [==============================] - 4317s 344ms/step - loss: 0.4317 - tp: 82023.0000 - fp: 15809.0000 - tn: 184419.0000 - fn: 18091.0000 - accuracy: 0.8871 - precision: 0.8384 - recall: 0.8193 - auc: 0.9475 - prc: 0.8998 - val_loss: 0.2269 - val_tp: 10088.0000 - val_fp: 973.0000 - val_tn: 21273.0000 - val_fn: 1035.0000 - val_accuracy: 0.9398 - val_precision: 0.9120 - val_recall: 0.9069 - val_auc: 0.9854 - val_prc: 0.9697 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "12515/12515 [==============================] - 4278s 342ms/step - loss: 0.2368 - tp: 91297.0000 - fp: 8270.0000 - tn: 191958.0000 - fn: 8817.0000 - accuracy: 0.9431 - precision: 0.9169 - recall: 0.9119 - auc: 0.9827 - prc: 0.9662 - val_loss: 0.2465 - val_tp: 10069.0000 - val_fp: 1033.0000 - val_tn: 21213.0000 - val_fn: 1054.0000 - val_accuracy: 0.9375 - val_precision: 0.9070 - val_recall: 0.9052 - val_auc: 0.9814 - val_prc: 0.9619 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "12515/12515 [==============================] - 4274s 342ms/step - loss: 0.1689 - tp: 94242.0000 - fp: 5599.0000 - tn: 194629.0000 - fn: 5872.0000 - accuracy: 0.9618 - precision: 0.9439 - recall: 0.9413 - auc: 0.9904 - prc: 0.9813 - val_loss: 0.2674 - val_tp: 9898.0000 - val_fp: 1205.0000 - val_tn: 21041.0000 - val_fn: 1225.0000 - val_accuracy: 0.9272 - val_precision: 0.8915 - val_recall: 0.8899 - val_auc: 0.9799 - val_prc: 0.9603 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "12515/12515 [==============================] - 4281s 342ms/step - loss: 0.1367 - tp: 95544.0000 - fp: 4442.0000 - tn: 195786.0000 - fn: 4570.0000 - accuracy: 0.9700 - precision: 0.9556 - recall: 0.9544 - auc: 0.9931 - prc: 0.9866 - val_loss: 0.2649 - val_tp: 10086.0000 - val_fp: 1030.0000 - val_tn: 21216.0000 - val_fn: 1037.0000 - val_accuracy: 0.9381 - val_precision: 0.9073 - val_recall: 0.9068 - val_auc: 0.9798 - val_prc: 0.9579 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "12515/12515 [==============================] - 4283s 342ms/step - loss: 0.0561 - tp: 98394.0000 - fp: 1663.0000 - tn: 198565.0000 - fn: 1720.0000 - accuracy: 0.9887 - precision: 0.9834 - recall: 0.9828 - auc: 0.9986 - prc: 0.9973 - val_loss: 0.1189 - val_tp: 10684.0000 - val_fp: 437.0000 - val_tn: 21809.0000 - val_fn: 439.0000 - val_accuracy: 0.9737 - val_precision: 0.9607 - val_recall: 0.9605 - val_auc: 0.9947 - val_prc: 0.9894 - lr: 2.0000e-05\n",
      "Epoch 6/100\n",
      "12515/12515 [==============================] - 4281s 342ms/step - loss: 0.0323 - tp: 99224.0000 - fp: 866.0000 - tn: 199362.0000 - fn: 890.0000 - accuracy: 0.9942 - precision: 0.9913 - recall: 0.9911 - auc: 0.9993 - prc: 0.9987 - val_loss: 0.1350 - val_tp: 10676.0000 - val_fp: 446.0000 - val_tn: 21800.0000 - val_fn: 447.0000 - val_accuracy: 0.9732 - val_precision: 0.9599 - val_recall: 0.9598 - val_auc: 0.9931 - val_prc: 0.9864 - lr: 2.0000e-05\n",
      "Epoch 7/100\n",
      "12515/12515 [==============================] - 4271s 341ms/step - loss: 0.0252 - tp: 99364.0000 - fp: 722.0000 - tn: 199506.0000 - fn: 750.0000 - accuracy: 0.9951 - precision: 0.9928 - recall: 0.9925 - auc: 0.9995 - prc: 0.9990 - val_loss: 0.1533 - val_tp: 10660.0000 - val_fp: 461.0000 - val_tn: 21785.0000 - val_fn: 463.0000 - val_accuracy: 0.9723 - val_precision: 0.9585 - val_recall: 0.9584 - val_auc: 0.9919 - val_prc: 0.9841 - lr: 2.0000e-05\n",
      "Epoch 8/100\n",
      "12515/12515 [==============================] - 4277s 342ms/step - loss: 0.0221 - tp: 99476.0000 - fp: 613.0000 - tn: 199615.0000 - fn: 638.0000 - accuracy: 0.9958 - precision: 0.9939 - recall: 0.9936 - auc: 0.9995 - prc: 0.9991 - val_loss: 0.1142 - val_tp: 10778.0000 - val_fp: 345.0000 - val_tn: 21901.0000 - val_fn: 345.0000 - val_accuracy: 0.9793 - val_precision: 0.9690 - val_recall: 0.9690 - val_auc: 0.9939 - val_prc: 0.9879 - lr: 2.0000e-05\n",
      "Epoch 9/100\n",
      "12515/12515 [==============================] - 4279s 342ms/step - loss: 0.0179 - tp: 99576.0000 - fp: 519.0000 - tn: 199709.0000 - fn: 538.0000 - accuracy: 0.9965 - precision: 0.9948 - recall: 0.9946 - auc: 0.9997 - prc: 0.9994 - val_loss: 0.0961 - val_tp: 10821.0000 - val_fp: 302.0000 - val_tn: 21944.0000 - val_fn: 302.0000 - val_accuracy: 0.9819 - val_precision: 0.9728 - val_recall: 0.9728 - val_auc: 0.9954 - val_prc: 0.9910 - lr: 2.0000e-05\n",
      "Epoch 10/100\n",
      "12515/12515 [==============================] - 4278s 342ms/step - loss: 0.0163 - tp: 99672.0000 - fp: 429.0000 - tn: 199799.0000 - fn: 442.0000 - accuracy: 0.9971 - precision: 0.9957 - recall: 0.9956 - auc: 0.9996 - prc: 0.9993 - val_loss: 0.1233 - val_tp: 10771.0000 - val_fp: 351.0000 - val_tn: 21895.0000 - val_fn: 352.0000 - val_accuracy: 0.9789 - val_precision: 0.9684 - val_recall: 0.9684 - val_auc: 0.9930 - val_prc: 0.9864 - lr: 2.0000e-05\n",
      "Epoch 11/100\n",
      "12515/12515 [==============================] - 4281s 342ms/step - loss: 0.0157 - tp: 99705.0000 - fp: 401.0000 - tn: 199827.0000 - fn: 409.0000 - accuracy: 0.9973 - precision: 0.9960 - recall: 0.9959 - auc: 0.9997 - prc: 0.9994 - val_loss: 0.0741 - val_tp: 10916.0000 - val_fp: 207.0000 - val_tn: 22039.0000 - val_fn: 207.0000 - val_accuracy: 0.9876 - val_precision: 0.9814 - val_recall: 0.9814 - val_auc: 0.9966 - val_prc: 0.9933 - lr: 2.0000e-05\n",
      "Epoch 12/100\n",
      "12515/12515 [==============================] - 4280s 342ms/step - loss: 0.0151 - tp: 99691.0000 - fp: 405.0000 - tn: 199823.0000 - fn: 423.0000 - accuracy: 0.9972 - precision: 0.9960 - recall: 0.9958 - auc: 0.9996 - prc: 0.9993 - val_loss: 0.0969 - val_tp: 10836.0000 - val_fp: 287.0000 - val_tn: 21959.0000 - val_fn: 287.0000 - val_accuracy: 0.9828 - val_precision: 0.9742 - val_recall: 0.9742 - val_auc: 0.9951 - val_prc: 0.9903 - lr: 2.0000e-05\n",
      "Epoch 13/100\n",
      "12515/12515 [==============================] - 4281s 342ms/step - loss: 0.0143 - tp: 99690.0000 - fp: 415.0000 - tn: 199813.0000 - fn: 424.0000 - accuracy: 0.9972 - precision: 0.9959 - recall: 0.9958 - auc: 0.9997 - prc: 0.9994 - val_loss: 0.1068 - val_tp: 10819.0000 - val_fp: 304.0000 - val_tn: 21942.0000 - val_fn: 304.0000 - val_accuracy: 0.9818 - val_precision: 0.9727 - val_recall: 0.9727 - val_auc: 0.9945 - val_prc: 0.9892 - lr: 2.0000e-05\n",
      "Epoch 14/100\n",
      "12515/12515 [==============================] - 4282s 342ms/step - loss: 0.0146 - tp: 99703.0000 - fp: 402.0000 - tn: 199826.0000 - fn: 411.0000 - accuracy: 0.9973 - precision: 0.9960 - recall: 0.9959 - auc: 0.9997 - prc: 0.9994 - val_loss: 0.1244 - val_tp: 10768.0000 - val_fp: 355.0000 - val_tn: 21891.0000 - val_fn: 355.0000 - val_accuracy: 0.9787 - val_precision: 0.9681 - val_recall: 0.9681 - val_auc: 0.9929 - val_prc: 0.9860 - lr: 2.0000e-05\n",
      "Epoch 15/100\n",
      "12515/12515 [==============================] - 4283s 342ms/step - loss: 0.0105 - tp: 99831.0000 - fp: 271.0000 - tn: 199957.0000 - fn: 283.0000 - accuracy: 0.9982 - precision: 0.9973 - recall: 0.9972 - auc: 0.9998 - prc: 0.9996 - val_loss: 0.1159 - val_tp: 10790.0000 - val_fp: 333.0000 - val_tn: 21913.0000 - val_fn: 333.0000 - val_accuracy: 0.9800 - val_precision: 0.9701 - val_recall: 0.9701 - val_auc: 0.9933 - val_prc: 0.9868 - lr: 4.0000e-06\n",
      "Epoch 16/100\n",
      "12515/12515 [==============================] - 4284s 342ms/step - loss: 0.0088 - tp: 99867.0000 - fp: 238.0000 - tn: 199990.0000 - fn: 247.0000 - accuracy: 0.9984 - precision: 0.9976 - recall: 0.9975 - auc: 0.9999 - prc: 0.9997 - val_loss: 0.1047 - val_tp: 10832.0000 - val_fp: 291.0000 - val_tn: 21955.0000 - val_fn: 291.0000 - val_accuracy: 0.9826 - val_precision: 0.9738 - val_recall: 0.9738 - val_auc: 0.9939 - val_prc: 0.9880 - lr: 4.0000e-06\n"
     ]
    }
   ],
   "source": [
    "inputs = pretrained_model.input\n",
    "x = augment(inputs)\n",
    "x = Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "\n",
    "\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.load_weights('/home/bkcs/NIMA/weights/EfficientNetB4_classification_weights_downsample_3cls(official)(500x500).h5')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    steps_per_epoch=len(train_images),\n",
    "    validation_data=val_images,\n",
    "    validation_steps=len(val_images),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        checkpoint_callback,\n",
    "        reduce_lr\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.42      0.25      0.32       630\n",
      "         Low       0.61      0.57      0.59      1542\n",
      "      Medium       0.96      0.97      0.96     25638\n",
      "\n",
      "    accuracy                           0.93     27810\n",
      "   macro avg       0.66      0.60      0.62     27810\n",
      "weighted avg       0.92      0.93      0.93     27810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  160,     0,   470],\n",
       "       [    0,   886,   656],\n",
       "       [  225,   578, 24835]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNetB4 testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Loss: 0.55753\n",
      "Test Accuracy: 87.10%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "pretrained_model = tf.keras.applications.efficientnet.EfficientNetB4(\n",
    "    input_shape=(224, 224, 3),\n",
    "    weights = 'imagenet',\n",
    "    include_top=False,\n",
    "    pooling='max'\n",
    ")\n",
    "inputs = pretrained_model.input\n",
    "x = augment(inputs)\n",
    "x = Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.load_weights('/home/bkcs/NIMA/weights/EfficientNetB4_classification_weights_upsample_3cls(official).h5')\n",
    "model.compile(\n",
    "    optimizer=Adam(0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.09      0.16      0.11       624\n",
      "         Low       0.18      0.57      0.27      1623\n",
      "      Medium       0.97      0.89      0.93     47578\n",
      "\n",
      "    accuracy                           0.87     49825\n",
      "   macro avg       0.41      0.54      0.44     49825\n",
      "weighted avg       0.94      0.87      0.90     49825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   97,     2,   525],\n",
       "       [    1,   928,   694],\n",
       "       [  985,  4220, 42373]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_5\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(1, 224, 224, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(1, 3) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m(pred[i]\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHigh\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     21\u001b[0m        model2\u001b[39m.\u001b[39mload_weights(\u001b[39m'\u001b[39m\u001b[39m/home/bkcs/NIMA/weights/efficientNetB2_weights_Medium(Best).h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m        score \u001b[39m=\u001b[39m model2\u001b[39m.\u001b[39;49mpredict(test_images[i], batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     23\u001b[0m        \u001b[39mprint\u001b[39m(test_df[\u001b[39m'\u001b[39m\u001b[39mFilepath\u001b[39m\u001b[39m'\u001b[39m][i],\u001b[39m\"\u001b[39m\u001b[39m : \u001b[39m\u001b[39m\"\u001b[39m, mean_score(score))\n\u001b[1;32m     24\u001b[0m \u001b[39m#score_list=[]\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m#score_dist_list=[]\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39m# for value in test_score:\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m# test_score_mean.append(mean_score(value))\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/bkcs/.local/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_5\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(1, 224, 224, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(1, 3) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "from utils.score_utils import mean_score\n",
    "from keras.applications.efficientnet import EfficientNetB2\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "image_size = 224\n",
    "base_model = EfficientNetB2(input_shape=(image_size, image_size, 3), include_top=False, pooling='avg', weights='imagenet')\n",
    "x = Dense(128, activation='relu')(base_model.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.75)(x)\n",
    "\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model2 = Model(base_model.input, x)\n",
    "for i in range(len(pred)):\n",
    "    if(pred[i]==\"High\"):\n",
    "       model2.load_weights('/home/bkcs/NIMA/weights/efficientNetB2_weights_Medium(Best).h5')\n",
    "       score = model2.predict(test_images[i], batch_size=1, verbose=0)[0]\n",
    "       print(test_df['Filepath'][i],\" : \", mean_score(score))\n",
    "#score_list=[]\n",
    "#score_dist_list=[]\n",
    "\n",
    "\n",
    "# scores = model2.predict(test_images, batch_size=1, verbose=0)[0]\n",
    "#         #score_dist_list.append(scores)\n",
    "# mean = mean_score(scores)\n",
    "        #print(mean)\n",
    "\n",
    "# score_list.append(mean)\n",
    "# #test_score_mean=[]\n",
    "# for value in test_score:\n",
    "# test_score_mean.append(mean_score(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on increasing resolution to 400x400 (downsampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Loss: 0.69030\n",
      "Test Accuracy: 3609000.00%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6229/6229 [==============================] - 490s 78ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.05      0.41      0.10       624\n",
      "         Low       0.13      0.74      0.22      1623\n",
      "      Medium       0.98      0.74      0.84     47578\n",
      "\n",
      "    accuracy                           0.73     49825\n",
      "   macro avg       0.39      0.63      0.38     49825\n",
      "weighted avg       0.94      0.73      0.81     49825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  253,    10,   361],\n",
       "       [    8,  1195,   420],\n",
       "       [ 4423,  8167, 34988]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on increasing resolution to 400x400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Loss: 0.46930\n",
      "Test Accuracy: 4683500.00%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6229/6229 [==============================] - 489s 78ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.11      0.04      0.06       624\n",
      "         Low       0.34      0.37      0.35      1623\n",
      "      Medium       0.97      0.97      0.97     47578\n",
      "\n",
      "    accuracy                           0.94     49825\n",
      "   macro avg       0.47      0.46      0.46     49825\n",
      "weighted avg       0.93      0.94      0.94     49825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   25,     0,   599],\n",
       "       [    0,   600,  1023],\n",
       "       [  202,  1166, 46210]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on undersampling to len(High)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Loss: 0.82073\n",
      "Test Accuracy: 65.08%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.48      0.72      0.58       607\n",
      "         Low       0.77      0.86      0.81      1578\n",
      "      Medium       0.35      0.08      0.13       650\n",
      "\n",
      "    accuracy                           0.65      2835\n",
      "   macro avg       0.53      0.55      0.51      2835\n",
      "weighted avg       0.61      0.65      0.60      2835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 439,  116,   52],\n",
       "       [ 180, 1354,   44],\n",
       "       [ 300,  298,   52]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on undersampling to len(Low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Loss: 0.86896\n",
      "Test Accuracy: 60.52%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.52      0.12      0.19       616\n",
      "         Low       0.72      0.68      0.70      1587\n",
      "      Medium       0.53      0.72      0.61      1563\n",
      "\n",
      "    accuracy                           0.61      3766\n",
      "   macro avg       0.59      0.51      0.50      3766\n",
      "weighted avg       0.61      0.61      0.58      3766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  71,   34,  511],\n",
       "       [   9, 1086,  492],\n",
       "       [  56,  385, 1122]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/PIL/TiffImagePlugin.py:822: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test Loss: 0.43153\n",
      "Test Accuracy: 89.34%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "pretrained_model = tf.keras.applications.vgg19.VGG19(\n",
    "    input_shape=(224, 224, 3),\n",
    "    # weights = 'imagenet',\n",
    "    include_top=False,\n",
    "    pooling='max'\n",
    ")\n",
    "inputs = pretrained_model.input\n",
    "x = Dense(128, activation='relu')(pretrained_model.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.45)(x)\n",
    "outputs = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.load_weights('/home/bkcs/NIMA/weights/VGG19_classification_weights_upsample(2).h5')\n",
    "model.compile(\n",
    "    optimizer=Adam(0.00001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.09      0.08      0.09       640\n",
      "         Low       0.16      0.41      0.23      1569\n",
      "      Medium       0.97      0.92      0.94     47617\n",
      "\n",
      "    accuracy                           0.89     49826\n",
      "   macro avg       0.41      0.47      0.42     49826\n",
      "weighted avg       0.93      0.89      0.91     49826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   53,     1,   586],\n",
       "       [    0,   643,   926],\n",
       "       [  534,  3262, 43821]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on outside dataset on oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 109983 validated image filenames belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "TARGET_SIZE = (400, 400)\n",
    "dataset = \"/home/bkcs/NIMA/Medium\"\n",
    "def convert_path_to_df(dataset):\n",
    "    image_dir = Path(dataset)\n",
    "\n",
    "    # Get filepaths and labels\n",
    "    filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.PNG'))\n",
    "\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    # Concatenate filepaths and labels\n",
    "    image_df = pd.concat([filepaths, labels], axis=1)\n",
    "    return image_df\n",
    "\n",
    "image_df = convert_path_to_df(dataset)\n",
    "\n",
    "# Separate in train and test data\n",
    "train_df, test_df = train_test_split(image_df, test_size=0.999, shuffle=True, random_state=42)\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,\n",
    ")\n",
    "\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/bkcs/NIMA/Medium/160409.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/bkcs/NIMA/Medium/754457.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/bkcs/NIMA/Medium/656600.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/bkcs/NIMA/Medium/461258.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/bkcs/NIMA/Medium/856981.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110088</th>\n",
       "      <td>/home/bkcs/NIMA/Medium/457255.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110089</th>\n",
       "      <td>/home/bkcs/NIMA/Medium/41128.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110090</th>\n",
       "      <td>/home/bkcs/NIMA/Medium/347293.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110091</th>\n",
       "      <td>/home/bkcs/NIMA/Medium/286644.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110092</th>\n",
       "      <td>/home/bkcs/NIMA/Medium/917254.jpg</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110093 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Filepath   Label\n",
       "0       /home/bkcs/NIMA/Medium/160409.jpg  Medium\n",
       "1       /home/bkcs/NIMA/Medium/754457.jpg  Medium\n",
       "2       /home/bkcs/NIMA/Medium/656600.jpg  Medium\n",
       "3       /home/bkcs/NIMA/Medium/461258.jpg  Medium\n",
       "4       /home/bkcs/NIMA/Medium/856981.jpg  Medium\n",
       "...                                   ...     ...\n",
       "110088  /home/bkcs/NIMA/Medium/457255.jpg  Medium\n",
       "110089   /home/bkcs/NIMA/Medium/41128.jpg  Medium\n",
       "110090  /home/bkcs/NIMA/Medium/347293.jpg  Medium\n",
       "110091  /home/bkcs/NIMA/Medium/286644.jpg  Medium\n",
       "110092  /home/bkcs/NIMA/Medium/917254.jpg  Medium\n",
       "\n",
       "[110093 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  345/13748 [..............................] - ETA: 18:45"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkcs/anaconda3/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10859/13748 [======================>.......] - ETA: 4:03"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkcs/anaconda3/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:858: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13748/13748 [==============================] - 1149s 83ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkcs/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.00      0.00      0.00         0\n",
      "         Low       0.00      0.00      0.00         0\n",
      "      Medium       1.00      0.89      0.94    109983\n",
      "\n",
      "    accuracy                           0.89    109983\n",
      "   macro avg       0.33      0.30      0.31    109983\n",
      "weighted avg       1.00      0.89      0.94    109983\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkcs/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bkcs/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0],\n",
       "       [    0,     0,     0],\n",
       "       [ 2629,  9631, 97723]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred, labels=list(labels.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
